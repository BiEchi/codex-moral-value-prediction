{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codex Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.7714401294498382\n",
      "AUC:  0.679943106563911\n",
      "ACC:  0.7026315789473684\n"
     ]
    }
   ],
   "source": [
    "preds = pd.read_json('../../../data/moral/inferred/codex/twitter/prompt/baseline-1ex-n1-t0.0/test.jsonl', lines=True)\n",
    "preds['pred'] = preds['instance_code'].apply(lambda x: x[0]).str[0].apply(lambda x: int(x))\n",
    "preds['label'] = preds['input'].apply(lambda x: x['original_example']['label'])\n",
    "\n",
    "# calculate the f1, auc, acc of the predictions\n",
    "f1 = f1_score(preds['label'], preds['pred'])\n",
    "auc = roc_auc_score(preds['label'], preds['pred'])\n",
    "acc = accuracy_score(preds['label'], preds['pred'])\n",
    "print(\"F1: \", f1)\n",
    "print(\"AUC: \", auc)\n",
    "print(\"ACC: \", acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codex Text Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.5370493253704932\n",
      "AUC:  0.7332285505529831\n",
      "ACC:  0.42134831460674155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moral_value</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>care_or_harm</td>\n",
       "      <td>0.583784</td>\n",
       "      <td>0.750674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fairness_or_cheating</td>\n",
       "      <td>0.554810</td>\n",
       "      <td>0.778727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loyalty_or_betrayal</td>\n",
       "      <td>0.392927</td>\n",
       "      <td>0.687867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>authority_or_subversion</td>\n",
       "      <td>0.368263</td>\n",
       "      <td>0.695774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>purity_or_degradation</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.673510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>non-moral</td>\n",
       "      <td>0.685675</td>\n",
       "      <td>0.735175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               moral_value        f1       auc\n",
       "0             care_or_harm  0.583784  0.750674\n",
       "1     fairness_or_cheating  0.554810  0.778727\n",
       "2      loyalty_or_betrayal  0.392927  0.687867\n",
       "3  authority_or_subversion  0.368263  0.695774\n",
       "4    purity_or_degradation  0.250000  0.673510\n",
       "5                non-moral  0.685675  0.735175"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.read_json('../../../data/moral/inferred/codex/twitter/prompt/baseline-50exwxp-n1-t0.0/test.jsonl', lines=True)\n",
    "# preds = pd.read_json('../../../data/moral/inferred/codex/twitter/prompt/baseline-3expmv-n1-t0.0/test.jsonl', lines=True)\n",
    "moral_value_list = ['care_or_harm', 'fairness_or_cheating', 'loyalty_or_betrayal', 'authority_or_subversion', 'purity_or_degradation', 'non-moral']\n",
    "preds['label'] = preds['input'].apply(lambda x: [1 if x['original_example'][moral_value] == 1 else 0 for moral_value in moral_value_list])\n",
    "preds['pred'] = preds['instance_code'].apply(lambda x:[1 if moral_value in x[0] else 0 for moral_value in moral_value_list])\n",
    "label = preds['label'].tolist()\n",
    "pred = preds['pred'].tolist()\n",
    "\n",
    "f1 = f1_score(label, pred, average='micro')\n",
    "auc = roc_auc_score(label, pred, average='micro')\n",
    "acc = accuracy_score(label, pred)\n",
    "\n",
    "print(\"F1: \", f1)\n",
    "print(\"AUC: \", auc)\n",
    "print(\"ACC: \", acc)\n",
    "\n",
    "f1_no_avg = f1_score(label, pred, average=None)\n",
    "auc_no_avg = roc_auc_score(label, pred, average=None)\n",
    "df = pd.DataFrame({'moral_value': moral_value_list, 'f1': f1_no_avg, 'auc': auc_no_avg})\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codex Code Multiclass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gold_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m     preds[moral_value] \u001b[39m=\u001b[39m preds[\u001b[39m'\u001b[39m\u001b[39minstance_code\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(moral_value \u001b[39min\u001b[39;00m x[\u001b[39m0\u001b[39m]))\n\u001b[1;32m     19\u001b[0m preds[\u001b[39m'\u001b[39m\u001b[39mnon-moral\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preds[moral_value_list[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msum() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m preds[\u001b[39m'\u001b[39m\u001b[39mannotation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preds[\u001b[39m'\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: [TWITTER_MORAL_SETS_REVERSE[moral_value] \u001b[39mfor\u001b[39;49;00m moral_value \u001b[39min\u001b[39;49;00m x[\u001b[39m'\u001b[39;49m\u001b[39moriginal_example\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mgold_classes\u001b[39;49m\u001b[39m'\u001b[39;49m]])\n\u001b[1;32m     21\u001b[0m preds[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preds[\u001b[39m'\u001b[39m\u001b[39mannotation\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m moral_value \u001b[39min\u001b[39;00m x \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m moral_value \u001b[39min\u001b[39;00m moral_value_list])\n\u001b[1;32m     22\u001b[0m preds[\u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preds[moral_value_list]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m x[moral_value] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m moral_value \u001b[39min\u001b[39;00m moral_value_list], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn [5], line 20\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     preds[moral_value] \u001b[39m=\u001b[39m preds[\u001b[39m'\u001b[39m\u001b[39minstance_code\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(moral_value \u001b[39min\u001b[39;00m x[\u001b[39m0\u001b[39m]))\n\u001b[1;32m     19\u001b[0m preds[\u001b[39m'\u001b[39m\u001b[39mnon-moral\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preds[moral_value_list[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msum() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m preds[\u001b[39m'\u001b[39m\u001b[39mannotation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preds[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [TWITTER_MORAL_SETS_REVERSE[moral_value] \u001b[39mfor\u001b[39;00m moral_value \u001b[39min\u001b[39;00m x[\u001b[39m'\u001b[39;49m\u001b[39moriginal_example\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mgold_classes\u001b[39;49m\u001b[39m'\u001b[39;49m]])\n\u001b[1;32m     21\u001b[0m preds[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preds[\u001b[39m'\u001b[39m\u001b[39mannotation\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m moral_value \u001b[39min\u001b[39;00m x \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m moral_value \u001b[39min\u001b[39;00m moral_value_list])\n\u001b[1;32m     22\u001b[0m preds[\u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preds[moral_value_list]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m x[moral_value] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m moral_value \u001b[39min\u001b[39;00m moral_value_list], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gold_classes'"
     ]
    }
   ],
   "source": [
    "TWITTER_MORAL_SETS_REVERSE = {\n",
    "    'care': 'care_or_harm',\n",
    "    'harm': 'care_or_harm',\n",
    "    'fairness': 'fairness_or_cheating',\n",
    "    'cheating': 'fairness_or_cheating',\n",
    "    'loyalty': 'loyalty_or_betrayal',\n",
    "    'betrayal': 'loyalty_or_betrayal',\n",
    "    'authority': 'authority_or_subversion',\n",
    "    'subversion': 'authority_or_subversion',\n",
    "    'purity': 'purity_or_degradation',\n",
    "    'degradation': 'purity_or_degradation',\n",
    "    'non-moral': 'non-moral'\n",
    "}\n",
    "\n",
    "preds = pd.read_json('../../../data/moral/inferred/codex/twitter/code/baseline-2expmv-n1-t0.0/test.jsonl', lines=True)\n",
    "moral_value_list = ['care_or_harm', 'fairness_or_cheating', 'loyalty_or_betrayal', 'authority_or_subversion', 'purity_or_degradation', 'non-moral']\n",
    "for moral_value in moral_value_list[:-1]:\n",
    "    preds[moral_value] = preds['instance_code'].apply(lambda x: int(moral_value in x[0]))\n",
    "preds['non-moral'] = preds[moral_value_list[:-1]].apply(lambda x: 1 if x.sum() == 0 else 0, axis=1)\n",
    "preds['annotation'] = preds['input'].apply(lambda x: [TWITTER_MORAL_SETS_REVERSE[moral_value] for moral_value in x['original_example']['gold_classes']])\n",
    "preds['label'] = preds['annotation'].apply(lambda x: [1 if moral_value in x else 0 for moral_value in moral_value_list])\n",
    "preds['pred'] = preds[moral_value_list].apply(lambda x: [1 if x[moral_value] == 1 else 0 for moral_value in moral_value_list], axis=1)\n",
    "\n",
    "label = preds['label'].tolist()\n",
    "pred = preds['pred'].tolist()\n",
    "\n",
    "f1 = f1_score(label, pred, average='micro')\n",
    "auc = roc_auc_score(label, pred, average='micro')\n",
    "acc = accuracy_score(label, pred)\n",
    "\n",
    "print(\"F1: \", f1)\n",
    "print(\"AUC: \", auc)\n",
    "print(\"ACC: \", acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.1499323410013532\n",
      "AUC:  0.4458123812565292\n",
      "ACC:  0.1392156862745098\n"
     ]
    }
   ],
   "source": [
    "preds = pd.read_json('../../../data/moral/inferred/codex/reddit/code/baseline-1ex-n1-t0.0/test.jsonl', lines=True)\n",
    "moral_value_list = ['Purity', 'Loyalty', 'Authority', 'Equality', 'Care', 'Proportionality', 'Non-Moral', 'Thin Morality']\n",
    "for moral_value in moral_value_list[:-2] + ['Thin Morality']:\n",
    "    preds[moral_value] = preds['instance_code'].apply(lambda x: int(moral_value in x[0]))\n",
    "preds['Non-Moral'] = preds[moral_value_list[:-2] + ['Thin Morality']].apply(lambda x: 1 if x.sum() == 0 or x['Thin Morality'] == 1 else 0, axis=1)\n",
    "preds.drop(columns=['Thin Morality'], inplace=True)\n",
    "preds['pred'] = preds[moral_value_list[:-1]].apply(lambda x: [1 if x[moral_value] == 1 else 0 for moral_value in moral_value_list[:-1]], axis=1)\n",
    "preds['label'] = preds['input'].apply(lambda x: [1 if moral_value in x['original_example']['gold_classes'] else 0 for moral_value in moral_value_list[:-1]])\n",
    "\n",
    "label = preds['label'].tolist()\n",
    "pred = preds['pred'].tolist()\n",
    "\n",
    "f1 = f1_score(label, pred, average='micro')\n",
    "auc = roc_auc_score(label, pred, average='micro')\n",
    "acc = accuracy_score(label, pred)\n",
    "\n",
    "print(\"F1: \", f1)\n",
    "print(\"AUC: \", auc)\n",
    "print(\"ACC: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c975a20906e8142c699e3b310c99f06555776b58f1706bf1df8dfa61229c3f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
